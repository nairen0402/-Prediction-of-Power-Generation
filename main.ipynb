{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**合併數據**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationCode</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>WindSpeed(m/s)</th>\n",
       "      <th>Pressure(hpa)</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Sunlight(Lux)</th>\n",
       "      <th>Power(mW)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2024-03-01 17:14:06.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.48</td>\n",
       "      <td>15.59</td>\n",
       "      <td>94.30</td>\n",
       "      <td>652.92</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2024-03-01 17:14:47.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.48</td>\n",
       "      <td>15.66</td>\n",
       "      <td>94.04</td>\n",
       "      <td>682.50</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2024-03-01 17:15:47.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.47</td>\n",
       "      <td>15.74</td>\n",
       "      <td>94.10</td>\n",
       "      <td>750.00</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2024-03-01 17:16:47.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.46</td>\n",
       "      <td>15.78</td>\n",
       "      <td>94.09</td>\n",
       "      <td>738.33</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2024-03-01 17:17:47.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.49</td>\n",
       "      <td>15.80</td>\n",
       "      <td>94.08</td>\n",
       "      <td>660.83</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375023</th>\n",
       "      <td>9</td>\n",
       "      <td>2024-10-18 14:27:02.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1006.65</td>\n",
       "      <td>33.09</td>\n",
       "      <td>52.98</td>\n",
       "      <td>5280.83</td>\n",
       "      <td>6.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375024</th>\n",
       "      <td>9</td>\n",
       "      <td>2024-10-18 14:28:02.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1006.67</td>\n",
       "      <td>33.07</td>\n",
       "      <td>53.42</td>\n",
       "      <td>4965.00</td>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375025</th>\n",
       "      <td>9</td>\n",
       "      <td>2024-10-18 14:29:02.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1006.68</td>\n",
       "      <td>32.92</td>\n",
       "      <td>53.73</td>\n",
       "      <td>4709.17</td>\n",
       "      <td>5.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375026</th>\n",
       "      <td>9</td>\n",
       "      <td>2024-10-18 14:30:02.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1006.70</td>\n",
       "      <td>32.92</td>\n",
       "      <td>53.55</td>\n",
       "      <td>4480.00</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375027</th>\n",
       "      <td>9</td>\n",
       "      <td>2024-10-18 14:31:02.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1006.67</td>\n",
       "      <td>32.98</td>\n",
       "      <td>53.51</td>\n",
       "      <td>4387.50</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1375028 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LocationCode                 DateTime  WindSpeed(m/s)  Pressure(hpa)  \\\n",
       "0                  10  2024-03-01 17:14:06.000             0.0        1017.48   \n",
       "1                  10  2024-03-01 17:14:47.000             0.0        1017.48   \n",
       "2                  10  2024-03-01 17:15:47.000             0.0        1017.47   \n",
       "3                  10  2024-03-01 17:16:47.000             0.0        1017.46   \n",
       "4                  10  2024-03-01 17:17:47.000             0.0        1017.49   \n",
       "...               ...                      ...             ...            ...   \n",
       "1375023             9  2024-10-18 14:27:02.000             0.0        1006.65   \n",
       "1375024             9  2024-10-18 14:28:02.000             0.0        1006.67   \n",
       "1375025             9  2024-10-18 14:29:02.000             0.0        1006.68   \n",
       "1375026             9  2024-10-18 14:30:02.000             0.0        1006.70   \n",
       "1375027             9  2024-10-18 14:31:02.000             0.0        1006.67   \n",
       "\n",
       "         Temperature(°C)  Humidity(%)  Sunlight(Lux)  Power(mW)  \n",
       "0                  15.59        94.30         652.92       0.12  \n",
       "1                  15.66        94.04         682.50       0.12  \n",
       "2                  15.74        94.10         750.00       0.14  \n",
       "3                  15.78        94.09         738.33       0.14  \n",
       "4                  15.80        94.08         660.83       0.12  \n",
       "...                  ...          ...            ...        ...  \n",
       "1375023            33.09        52.98        5280.83       6.71  \n",
       "1375024            33.07        53.42        4965.00       5.74  \n",
       "1375025            32.92        53.73        4709.17       5.13  \n",
       "1375026            32.92        53.55        4480.00       4.69  \n",
       "1375027            32.98        53.51        4387.50       4.35  \n",
       "\n",
       "[1375028 rows x 8 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "folder_path = './Training data/'\n",
    "files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "data = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**合併地點與時間**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationCode</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>WindSpeed(m/s)</th>\n",
       "      <th>Pressure(hpa)</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Sunlight(Lux)</th>\n",
       "      <th>Power(mW)</th>\n",
       "      <th>DateLoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>656248</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 06:31:08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.50</td>\n",
       "      <td>17.5</td>\n",
       "      <td>86.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2024010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656249</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 06:32:08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.53</td>\n",
       "      <td>17.5</td>\n",
       "      <td>86.7</td>\n",
       "      <td>28.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2024010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656250</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 06:33:08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.57</td>\n",
       "      <td>17.5</td>\n",
       "      <td>86.7</td>\n",
       "      <td>32.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2024010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656251</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 06:34:08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.58</td>\n",
       "      <td>17.5</td>\n",
       "      <td>86.7</td>\n",
       "      <td>39.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2024010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656252</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 06:35:08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.59</td>\n",
       "      <td>17.5</td>\n",
       "      <td>86.7</td>\n",
       "      <td>45.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2024010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656243</th>\n",
       "      <td>17</td>\n",
       "      <td>2024-07-12 15:26:46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1004.05</td>\n",
       "      <td>36.5</td>\n",
       "      <td>65.4</td>\n",
       "      <td>12315.00</td>\n",
       "      <td>35.91</td>\n",
       "      <td>2024071217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656244</th>\n",
       "      <td>17</td>\n",
       "      <td>2024-07-12 15:27:47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1004.08</td>\n",
       "      <td>36.5</td>\n",
       "      <td>64.7</td>\n",
       "      <td>12692.50</td>\n",
       "      <td>38.23</td>\n",
       "      <td>2024071217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656245</th>\n",
       "      <td>17</td>\n",
       "      <td>2024-07-12 15:28:47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1004.10</td>\n",
       "      <td>36.5</td>\n",
       "      <td>64.5</td>\n",
       "      <td>12960.00</td>\n",
       "      <td>39.95</td>\n",
       "      <td>2024071217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656246</th>\n",
       "      <td>17</td>\n",
       "      <td>2024-07-12 15:29:47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>36.4</td>\n",
       "      <td>64.9</td>\n",
       "      <td>12751.67</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2024071217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656247</th>\n",
       "      <td>17</td>\n",
       "      <td>2024-07-12 15:30:47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1004.07</td>\n",
       "      <td>36.4</td>\n",
       "      <td>64.9</td>\n",
       "      <td>12288.33</td>\n",
       "      <td>34.87</td>\n",
       "      <td>2024071217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1375028 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        LocationCode            DateTime  WindSpeed(m/s)  Pressure(hpa)  \\\n",
       "656248             1 2024-01-01 06:31:08             0.0        1016.50   \n",
       "656249             1 2024-01-01 06:32:08             0.0        1016.53   \n",
       "656250             1 2024-01-01 06:33:08             0.0        1016.57   \n",
       "656251             1 2024-01-01 06:34:08             0.0        1016.58   \n",
       "656252             1 2024-01-01 06:35:08             0.0        1016.59   \n",
       "...              ...                 ...             ...            ...   \n",
       "656243            17 2024-07-12 15:26:46             0.0        1004.05   \n",
       "656244            17 2024-07-12 15:27:47             0.0        1004.08   \n",
       "656245            17 2024-07-12 15:28:47             0.0        1004.10   \n",
       "656246            17 2024-07-12 15:29:47             0.0        1004.11   \n",
       "656247            17 2024-07-12 15:30:47             0.0        1004.07   \n",
       "\n",
       "        Temperature(°C)  Humidity(%)  Sunlight(Lux)  Power(mW)     DateLoc  \n",
       "656248             17.5         86.8          25.00       0.00  2024010101  \n",
       "656249             17.5         86.7          28.33       0.00  2024010101  \n",
       "656250             17.5         86.7          32.50       0.00  2024010101  \n",
       "656251             17.5         86.7          39.17       0.00  2024010101  \n",
       "656252             17.5         86.7          45.83       0.00  2024010101  \n",
       "...                 ...          ...            ...        ...         ...  \n",
       "656243             36.5         65.4       12315.00      35.91  2024071217  \n",
       "656244             36.5         64.7       12692.50      38.23  2024071217  \n",
       "656245             36.5         64.5       12960.00      39.95  2024071217  \n",
       "656246             36.4         64.9       12751.67      38.51  2024071217  \n",
       "656247             36.4         64.9       12288.33      34.87  2024071217  \n",
       "\n",
       "[1375028 rows x 9 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "data = data.sort_values(by=['LocationCode', 'DateTime'])\n",
    "#data['Combined'] =  pd.to_datetime(data['DateTime']).dt.strftime('%Y%m%d%H%M') + data['LocationCode'].apply(lambda x: f'{x:02}')\n",
    "data['DateLoc'] = data['DateTime'].dt.strftime('%Y%m%d') + data['LocationCode'].apply(lambda x : f'{x:02}')\n",
    "data.to_csv('combined.csv', index=False)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**讀取日期**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_file = 'upload.csv'\n",
    "target_data = pd.read_csv(upload_file)\n",
    "target_set = set()\n",
    "\n",
    "target_data['Date'] = target_data['序號'].astype(str).str[:8]\n",
    "target_data['LocationCode'] = target_data['序號'].astype(str).str[12:14]\n",
    "\n",
    "target_data['DateLoc'] = target_data['Date'] + target_data['LocationCode']\n",
    "target_set.update(target_data['DateLoc'].unique())\n",
    "len(target_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**分割題目**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[~data['DateLoc'].isin(target_set)]\n",
    "input_data = data[data['DateLoc'].isin(target_set)]\n",
    "input_data.to_csv('input.csv', index=False)\n",
    "train_data.to_csv('train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**異常值處理**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SunLight(Lux)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "filtered_data = train_data[train_data['Sunlight(Lux)'] != 117758.2]\n",
    "# 特徵與標籤\n",
    "X = filtered_data[['Power(mW)']]  # 發電量 (特徵)\n",
    "y = filtered_data['Sunlight(Lux)']  # 光照度 (目標)\n",
    "# 分割訓練與測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型係數: 55.60570241742195\n",
      "模型截距: 7422.522839557063\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 建立線性回歸模型\n",
    "model = LinearRegression()\n",
    "\n",
    "# 訓練模型\n",
    "model.fit( X_train,y_train )\n",
    "\n",
    "# 獲取模型係數與截距\n",
    "print(f\"模型係數: {model.coef_[0]}\")  # 光照度對發電量的影響係數\n",
    "print(f\"模型截距: {model.intercept_}\")  # 發電量基線\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 99281509.20590872\n",
      "R2: 0.8667737009319059\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 預測\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 計算誤差與解釋力\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用回歸模型補充異常光照度對應的發電量\n",
    "data.loc[data['Sunlight(Lux)'] == 117758.2, 'Sunlight(Lux)'] = \\\n",
    "    model.predict(data[data['Sunlight(Lux)'] == 117758.2][['Power(mW)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationCode</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>WindSpeed(m/s)</th>\n",
       "      <th>Pressure(hpa)</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Sunlight(Lux)</th>\n",
       "      <th>Power(mW)</th>\n",
       "      <th>DateLoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>656248</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 06:31:08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.50</td>\n",
       "      <td>17.5</td>\n",
       "      <td>86.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2024010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656249</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 06:32:08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.53</td>\n",
       "      <td>17.5</td>\n",
       "      <td>86.7</td>\n",
       "      <td>28.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2024010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656250</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 06:33:08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.57</td>\n",
       "      <td>17.5</td>\n",
       "      <td>86.7</td>\n",
       "      <td>32.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2024010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656251</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 06:34:08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.58</td>\n",
       "      <td>17.5</td>\n",
       "      <td>86.7</td>\n",
       "      <td>39.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2024010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656252</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 06:35:08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.59</td>\n",
       "      <td>17.5</td>\n",
       "      <td>86.7</td>\n",
       "      <td>45.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2024010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656243</th>\n",
       "      <td>17</td>\n",
       "      <td>2024-07-12 15:26:46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1004.05</td>\n",
       "      <td>36.5</td>\n",
       "      <td>65.4</td>\n",
       "      <td>12315.00</td>\n",
       "      <td>35.91</td>\n",
       "      <td>2024071217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656244</th>\n",
       "      <td>17</td>\n",
       "      <td>2024-07-12 15:27:47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1004.08</td>\n",
       "      <td>36.5</td>\n",
       "      <td>64.7</td>\n",
       "      <td>12692.50</td>\n",
       "      <td>38.23</td>\n",
       "      <td>2024071217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656245</th>\n",
       "      <td>17</td>\n",
       "      <td>2024-07-12 15:28:47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1004.10</td>\n",
       "      <td>36.5</td>\n",
       "      <td>64.5</td>\n",
       "      <td>12960.00</td>\n",
       "      <td>39.95</td>\n",
       "      <td>2024071217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656246</th>\n",
       "      <td>17</td>\n",
       "      <td>2024-07-12 15:29:47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1004.11</td>\n",
       "      <td>36.4</td>\n",
       "      <td>64.9</td>\n",
       "      <td>12751.67</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2024071217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656247</th>\n",
       "      <td>17</td>\n",
       "      <td>2024-07-12 15:30:47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1004.07</td>\n",
       "      <td>36.4</td>\n",
       "      <td>64.9</td>\n",
       "      <td>12288.33</td>\n",
       "      <td>34.87</td>\n",
       "      <td>2024071217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1375028 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        LocationCode            DateTime  WindSpeed(m/s)  Pressure(hpa)  \\\n",
       "656248             1 2024-01-01 06:31:08             0.0        1016.50   \n",
       "656249             1 2024-01-01 06:32:08             0.0        1016.53   \n",
       "656250             1 2024-01-01 06:33:08             0.0        1016.57   \n",
       "656251             1 2024-01-01 06:34:08             0.0        1016.58   \n",
       "656252             1 2024-01-01 06:35:08             0.0        1016.59   \n",
       "...              ...                 ...             ...            ...   \n",
       "656243            17 2024-07-12 15:26:46             0.0        1004.05   \n",
       "656244            17 2024-07-12 15:27:47             0.0        1004.08   \n",
       "656245            17 2024-07-12 15:28:47             0.0        1004.10   \n",
       "656246            17 2024-07-12 15:29:47             0.0        1004.11   \n",
       "656247            17 2024-07-12 15:30:47             0.0        1004.07   \n",
       "\n",
       "        Temperature(°C)  Humidity(%)  Sunlight(Lux)  Power(mW)     DateLoc  \n",
       "656248             17.5         86.8          25.00       0.00  2024010101  \n",
       "656249             17.5         86.7          28.33       0.00  2024010101  \n",
       "656250             17.5         86.7          32.50       0.00  2024010101  \n",
       "656251             17.5         86.7          39.17       0.00  2024010101  \n",
       "656252             17.5         86.7          45.83       0.00  2024010101  \n",
       "...                 ...          ...            ...        ...         ...  \n",
       "656243             36.5         65.4       12315.00      35.91  2024071217  \n",
       "656244             36.5         64.7       12692.50      38.23  2024071217  \n",
       "656245             36.5         64.5       12960.00      39.95  2024071217  \n",
       "656246             36.4         64.9       12751.67      38.51  2024071217  \n",
       "656247             36.4         64.9       12288.33      34.87  2024071217  \n",
       "\n",
       "[1375028 rows x 9 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**use Lstm and pre-processed data to train our model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Pressure(hpa)', 'Temperature(°C)', \n",
    "            'Humidity(%)', 'Sunlight(Lux)']\n",
    "X = train_data[features]\n",
    "y = train_data['Power(mW)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_sequences(X, y, time_steps, forecast_steps=1):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - time_steps - forecast_steps + 1):\n",
    "        X_seq.append(X.iloc[i:i+time_steps].values)\n",
    "        y_seq.append(y.iloc[i+time_steps:i+time_steps+forecast_steps].values)\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "time_steps = 10  # 每次輸入的時間步長\n",
    "X_seq, y_seq = create_sequences(X, y, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeffi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(time_steps, len(features)) ,return_sequences=True),\n",
    "    LSTM(30, activation='relu'),  # 添加第二層 LSTM\n",
    "    Dense(1)  # 預測單一數值\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3330/3330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 8ms/step - loss: 534345.0625 - mae: 280.3209 - val_loss: 45462.4023 - val_mae: 119.1962\n",
      "Epoch 2/10\n",
      "\u001b[1m3330/3330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - loss: 45679.9219 - mae: 116.6667 - val_loss: 44184.4258 - val_mae: 105.5681\n",
      "Epoch 3/10\n",
      "\u001b[1m3330/3330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - loss: 43702.8398 - mae: 102.7432 - val_loss: 44797.0352 - val_mae: 109.8198\n",
      "Epoch 4/10\n",
      "\u001b[1m3330/3330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - loss: 42919.9258 - mae: 103.9022 - val_loss: 40403.7773 - val_mae: 86.4529\n",
      "Epoch 5/10\n",
      "\u001b[1m3330/3330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - loss: 38879.9883 - mae: 84.0723 - val_loss: 38737.7969 - val_mae: 81.0421\n",
      "Epoch 6/10\n",
      "\u001b[1m3330/3330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - loss: 38753.5781 - mae: 82.1412 - val_loss: 38892.6602 - val_mae: 86.6607\n",
      "Epoch 7/10\n",
      "\u001b[1m3330/3330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - loss: 38500.1133 - mae: 81.5988 - val_loss: 38084.0000 - val_mae: 81.3707\n",
      "Epoch 8/10\n",
      "\u001b[1m3330/3330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - loss: 37409.0156 - mae: 78.9902 - val_loss: 38991.4805 - val_mae: 82.7677\n",
      "Epoch 9/10\n",
      "\u001b[1m3330/3330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - loss: 39060.5859 - mae: 82.7863 - val_loss: 38421.6406 - val_mae: 83.6573\n",
      "Epoch 10/10\n",
      "\u001b[1m3330/3330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 8ms/step - loss: 37750.4258 - mae: 81.5782 - val_loss: 38241.0195 - val_mae: 80.8837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e11cf83680>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=256, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('./models/trained_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8323/8323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      "預測結果已成功儲存到 predictions.csv！\n",
      "Prediction\n",
      "-5.905686       18\n",
      " 1588.765503     3\n",
      " 18.906723       3\n",
      "-0.719056        3\n",
      "-1.205362        2\n",
      "                ..\n",
      " 1219.819946     1\n",
      " 1002.174255     1\n",
      " 98.385536       1\n",
      "-1.667245        1\n",
      "-1.558442        1\n",
      "Name: count, Length: 265168, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Prediction'])\n",
    "\n",
    "# 將 DataFrame 存成 CSV\n",
    "predictions_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "print(\"預測結果已成功儲存到 predictions.csv！\")\n",
    "print(predictions_df['Prediction'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Id': ['202402180900{:02d}'.format(i) for i in range(1, len(predictions) + 1)],\n",
    "    'Power(mW)': predictions.flatten().round(2)\n",
    "})\n",
    "\n",
    "results.to_csv('upload(test).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 0 2024010601.csv\n",
      "Saved: 1 2024011101.csv\n",
      "Saved: 2 2024011701.csv\n",
      "Saved: 3 2024011901.csv\n",
      "Saved: 4 2024012317.csv\n",
      "Saved: 5 2024012408.csv\n",
      "Saved: 6 2024012502.csv\n",
      "Saved: 7 2024012802.csv\n",
      "Saved: 8 2024012808.csv\n",
      "Saved: 9 2024012917.csv\n",
      "Saved: 10 2024020408.csv\n",
      "Saved: 11 2024020717.csv\n",
      "Saved: 12 2024021301.csv\n",
      "Saved: 13 2024021302.csv\n",
      "Saved: 14 2024021413.csv\n",
      "Saved: 15 2024021515.csv\n",
      "Saved: 16 2024021517.csv\n",
      "Saved: 17 2024021808.csv\n",
      "Saved: 18 2024021815.csv\n",
      "Saved: 19 2024021817.csv\n",
      "Saved: 20 2024022113.csv\n",
      "Saved: 21 2024022401.csv\n",
      "Saved: 22 2024022417.csv\n",
      "Saved: 23 2024022514.csv\n",
      "Saved: 24 2024022601.csv\n",
      "Saved: 25 2024022602.csv\n",
      "Saved: 26 2024022714.csv\n",
      "Saved: 27 2024030508.csv\n",
      "Saved: 28 2024030517.csv\n",
      "Saved: 29 2024030710.csv\n",
      "Saved: 30 2024030909.csv\n",
      "Saved: 31 2024030917.csv\n",
      "Saved: 32 2024031010.csv\n",
      "Saved: 33 2024031117.csv\n",
      "Saved: 34 2024031409.csv\n",
      "Saved: 35 2024031413.csv\n",
      "Saved: 36 2024031415.csv\n",
      "Saved: 37 2024031512.csv\n",
      "Saved: 38 2024031610.csv\n",
      "Saved: 39 2024031613.csv\n",
      "Saved: 40 2024031616.csv\n",
      "Saved: 41 2024031703.csv\n",
      "Saved: 42 2024031712.csv\n",
      "Saved: 43 2024031715.csv\n",
      "Saved: 44 2024031817.csv\n",
      "Saved: 45 2024031902.csv\n",
      "Saved: 46 2024032211.csv\n",
      "Saved: 47 2024032216.csv\n",
      "Saved: 48 2024032410.csv\n",
      "Saved: 49 2024032508.csv\n",
      "Saved: 50 2024032701.csv\n",
      "Saved: 51 2024032711.csv\n",
      "Saved: 52 2024032714.csv\n",
      "Saved: 53 2024032808.csv\n",
      "Saved: 54 2024032813.csv\n",
      "Saved: 55 2024032901.csv\n",
      "Saved: 56 2024040317.csv\n",
      "Saved: 57 2024041210.csv\n",
      "Saved: 58 2024041212.csv\n",
      "Saved: 59 2024041213.csv\n",
      "Saved: 60 2024041215.csv\n",
      "Saved: 61 2024041311.csv\n",
      "Saved: 62 2024041403.csv\n",
      "Saved: 63 2024041409.csv\n",
      "Saved: 64 2024041416.csv\n",
      "Saved: 65 2024041714.csv\n",
      "Saved: 66 2024041910.csv\n",
      "Saved: 67 2024042004.csv\n",
      "Saved: 68 2024042204.csv\n",
      "Saved: 69 2024042216.csv\n",
      "Saved: 70 2024042310.csv\n",
      "Saved: 71 2024042611.csv\n",
      "Saved: 72 2024042612.csv\n",
      "Saved: 73 2024042702.csv\n",
      "Saved: 74 2024042801.csv\n",
      "Saved: 75 2024043001.csv\n",
      "Saved: 76 2024050609.csv\n",
      "Saved: 77 2024050717.csv\n",
      "Saved: 78 2024050801.csv\n",
      "Saved: 79 2024050802.csv\n",
      "Saved: 80 2024050808.csv\n",
      "Saved: 81 2024050905.csv\n",
      "Saved: 82 2024050917.csv\n",
      "Saved: 83 2024051001.csv\n",
      "Saved: 84 2024051304.csv\n",
      "Saved: 85 2024051316.csv\n",
      "Saved: 86 2024051405.csv\n",
      "Saved: 87 2024051501.csv\n",
      "Saved: 88 2024051504.csv\n",
      "Saved: 89 2024051510.csv\n",
      "Saved: 90 2024051714.csv\n",
      "Saved: 91 2024051716.csv\n",
      "Saved: 92 2024051808.csv\n",
      "Saved: 93 2024051815.csv\n",
      "Saved: 94 2024051910.csv\n",
      "Saved: 95 2024051916.csv\n",
      "Saved: 96 2024052001.csv\n",
      "Saved: 97 2024052006.csv\n",
      "Saved: 98 2024052108.csv\n",
      "Saved: 99 2024052112.csv\n",
      "Saved: 100 2024052401.csv\n",
      "Saved: 101 2024052403.csv\n",
      "Saved: 102 2024052603.csv\n",
      "Saved: 103 2024052607.csv\n",
      "Saved: 104 2024052608.csv\n",
      "Saved: 105 2024052609.csv\n",
      "Saved: 106 2024052610.csv\n",
      "Saved: 107 2024052706.csv\n",
      "Saved: 108 2024052817.csv\n",
      "Saved: 109 2024052908.csv\n",
      "Saved: 110 2024053015.csv\n",
      "Saved: 111 2024060217.csv\n",
      "Saved: 112 2024060303.csv\n",
      "Saved: 113 2024060417.csv\n",
      "Saved: 114 2024060515.csv\n",
      "Saved: 115 2024060611.csv\n",
      "Saved: 116 2024060708.csv\n",
      "Saved: 117 2024060816.csv\n",
      "Saved: 118 2024060917.csv\n",
      "Saved: 119 2024061207.csv\n",
      "Saved: 120 2024061301.csv\n",
      "Saved: 121 2024061308.csv\n",
      "Saved: 122 2024061409.csv\n",
      "Saved: 123 2024061417.csv\n",
      "Saved: 124 2024061501.csv\n",
      "Saved: 125 2024061505.csv\n",
      "Saved: 126 2024061507.csv\n",
      "Saved: 127 2024061710.csv\n",
      "Saved: 128 2024061808.csv\n",
      "Saved: 129 2024061910.csv\n",
      "Saved: 130 2024061912.csv\n",
      "Saved: 131 2024061913.csv\n",
      "Saved: 132 2024061917.csv\n",
      "Saved: 133 2024062003.csv\n",
      "Saved: 134 2024062005.csv\n",
      "Saved: 135 2024062109.csv\n",
      "Saved: 136 2024062112.csv\n",
      "Saved: 137 2024062301.csv\n",
      "Saved: 138 2024062506.csv\n",
      "Saved: 139 2024062701.csv\n",
      "Saved: 140 2024062717.csv\n",
      "Saved: 141 2024062808.csv\n",
      "Saved: 142 2024062809.csv\n",
      "Saved: 143 2024062904.csv\n",
      "Saved: 144 2024062906.csv\n",
      "Saved: 145 2024062916.csv\n",
      "Saved: 146 2024062917.csv\n",
      "Saved: 147 2024063008.csv\n",
      "Saved: 148 2024063010.csv\n",
      "Saved: 149 2024070208.csv\n",
      "Saved: 150 2024070301.csv\n",
      "Saved: 151 2024070404.csv\n",
      "Saved: 152 2024070414.csv\n",
      "Saved: 153 2024070415.csv\n",
      "Saved: 154 2024070417.csv\n",
      "Saved: 155 2024070502.csv\n",
      "Saved: 156 2024070508.csv\n",
      "Saved: 157 2024070512.csv\n",
      "Saved: 158 2024070605.csv\n",
      "Saved: 159 2024070606.csv\n",
      "Saved: 160 2024070617.csv\n",
      "Saved: 161 2024070701.csv\n",
      "Saved: 162 2024070702.csv\n",
      "Saved: 163 2024070805.csv\n",
      "Saved: 164 2024070908.csv\n",
      "Saved: 165 2024070917.csv\n",
      "Saved: 166 2024071110.csv\n",
      "Saved: 167 2024071211.csv\n",
      "Saved: 168 2024071301.csv\n",
      "Saved: 169 2024071312.csv\n",
      "Saved: 170 2024071410.csv\n",
      "Saved: 171 2024071501.csv\n",
      "Saved: 172 2024071508.csv\n",
      "Saved: 173 2024071514.csv\n",
      "Saved: 174 2024071707.csv\n",
      "Saved: 175 2024071709.csv\n",
      "Saved: 176 2024071810.csv\n",
      "Saved: 177 2024071908.csv\n",
      "Saved: 178 2024072010.csv\n",
      "Saved: 179 2024072206.csv\n",
      "Saved: 180 2024081208.csv\n",
      "Saved: 181 2024082808.csv\n",
      "Saved: 182 2024091807.csv\n",
      "Saved: 183 2024091912.csv\n",
      "Saved: 184 2024092007.csv\n",
      "Saved: 185 2024092010.csv\n",
      "Saved: 186 2024092208.csv\n",
      "Saved: 187 2024092209.csv\n",
      "Saved: 188 2024092312.csv\n",
      "Saved: 189 2024092704.csv\n",
      "Saved: 190 2024092808.csv\n",
      "Saved: 191 2024092809.csv\n",
      "Saved: 192 2024092810.csv\n",
      "Saved: 193 2024100212.csv\n",
      "Saved: 194 2024101108.csv\n",
      "Saved: 195 2024101607.csv\n",
      "Saved: 196 2024101608.csv\n",
      "Saved: 197 2024101804.csv\n",
      "Saved: 198 2024101808.csv\n",
      "Saved: 199 2024102808.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 讀取數據\n",
    "df = pd.read_csv('input.csv')\n",
    "\n",
    "# 設定儲存資料夾路徑\n",
    "output_folder = './inputdata'\n",
    "# 如果資料夾不存在，則創建資料夾\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# 根據日期分割數據並儲存為 CSV 文件\n",
    "index = 0\n",
    "for date, group in df.groupby('DateLoc'):\n",
    "    # 設定每個分組儲存的文件名稱\n",
    "    filename = f\"{date}.csv\"\n",
    "    file_path = os.path.join(output_folder, filename)\n",
    "    \n",
    "    # 儲存該分組的 CSV 文件\n",
    "    group.to_csv(file_path, index=False)\n",
    "    print(f\"Saved: {index} {filename}\")\n",
    "    index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeffi\\AppData\\Local\\Temp\\ipykernel_15516\\3454176487.py:33: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '<DatetimeArray>\n",
      "['2024-01-17 09:00:01', '2024-01-17 09:10:01', '2024-01-17 09:20:01',\n",
      " '2024-01-17 09:30:01', '2024-01-17 09:40:01', '2024-01-17 09:50:01',\n",
      " '2024-01-17 10:00:01', '2024-01-17 10:10:01', '2024-01-17 10:20:01',\n",
      " '2024-01-17 10:30:01', '2024-01-17 10:40:01', '2024-01-17 10:50:01',\n",
      " '2024-01-17 11:00:01', '2024-01-17 11:10:01', '2024-01-17 11:20:01',\n",
      " '2024-01-17 11:30:01', '2024-01-17 11:40:01', '2024-01-17 11:50:01',\n",
      " '2024-01-17 12:00:01', '2024-01-17 12:10:01', '2024-01-17 12:20:01',\n",
      " '2024-01-17 12:30:01', '2024-01-17 12:40:01', '2024-01-17 12:50:01',\n",
      " '2024-01-17 13:00:01', '2024-01-17 13:10:01', '2024-01-17 13:20:01',\n",
      " '2024-01-17 13:30:01', '2024-01-17 13:40:01', '2024-01-17 13:50:01',\n",
      " '2024-01-17 14:00:01', '2024-01-17 14:10:01', '2024-01-17 14:20:01',\n",
      " '2024-01-17 14:30:01', '2024-01-17 14:40:01', '2024-01-17 14:50:01',\n",
      " '2024-01-17 15:00:01', '2024-01-17 15:10:01', '2024-01-17 15:20:01',\n",
      " '2024-01-17 15:30:01', '2024-01-17 15:40:01', '2024-01-17 15:50:01',\n",
      " '2024-01-17 16:00:01', '2024-01-17 16:10:01', '2024-01-17 16:20:01',\n",
      " '2024-01-17 16:30:01', '2024-01-17 16:40:01', '2024-01-17 16:50:01']\n",
      "Length: 48, dtype: datetime64[ns]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  filtered_df.loc[:, '序號'] = pd.to_datetime(filtered_df['序號'], format='%Y%m%d%H%M%S')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "序號: 20240117090001, 預測瓦數: 169.39\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeffi\\AppData\\Local\\Temp\\ipykernel_15516\\3454176487.py:33: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '<DatetimeArray>\n",
      "['2024-01-17 09:00:01', '2024-01-17 09:10:01', '2024-01-17 09:20:01',\n",
      " '2024-01-17 09:30:01', '2024-01-17 09:40:01', '2024-01-17 09:50:01',\n",
      " '2024-01-17 10:00:01', '2024-01-17 10:10:01', '2024-01-17 10:20:01',\n",
      " '2024-01-17 10:30:01', '2024-01-17 10:40:01', '2024-01-17 10:50:01',\n",
      " '2024-01-17 11:00:01', '2024-01-17 11:10:01', '2024-01-17 11:20:01',\n",
      " '2024-01-17 11:30:01', '2024-01-17 11:40:01', '2024-01-17 11:50:01',\n",
      " '2024-01-17 12:00:01', '2024-01-17 12:10:01', '2024-01-17 12:20:01',\n",
      " '2024-01-17 12:30:01', '2024-01-17 12:40:01', '2024-01-17 12:50:01',\n",
      " '2024-01-17 13:00:01', '2024-01-17 13:10:01', '2024-01-17 13:20:01',\n",
      " '2024-01-17 13:30:01', '2024-01-17 13:40:01', '2024-01-17 13:50:01',\n",
      " '2024-01-17 14:00:01', '2024-01-17 14:10:01', '2024-01-17 14:20:01',\n",
      " '2024-01-17 14:30:01', '2024-01-17 14:40:01', '2024-01-17 14:50:01',\n",
      " '2024-01-17 15:00:01', '2024-01-17 15:10:01', '2024-01-17 15:20:01',\n",
      " '2024-01-17 15:30:01', '2024-01-17 15:40:01', '2024-01-17 15:50:01',\n",
      " '2024-01-17 16:00:01', '2024-01-17 16:10:01', '2024-01-17 16:20:01',\n",
      " '2024-01-17 16:30:01', '2024-01-17 16:40:01', '2024-01-17 16:50:01']\n",
      "Length: 48, dtype: datetime64[ns]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  filtered_df.loc[:, '序號'] = pd.to_datetime(filtered_df['序號'], format='%Y%m%d%H%M%S')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 89\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m預測結果已成功儲存到 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m！\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# 執行結果生成\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m \u001b[43mgenerate_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mupload_predictions.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[98], line 73\u001b[0m, in \u001b[0;36mgenerate_predictions\u001b[1;34m(target_data, features, output_file)\u001b[0m\n\u001b[0;32m     70\u001b[0m end_time \u001b[38;5;241m=\u001b[39m start_time \u001b[38;5;241m+\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimedelta(minutes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m59\u001b[39m)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# 預測該時間範圍內的瓦數\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m avg_power \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_minute_power\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDateLoc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# 添加結果到列表\u001b[39;00m\n\u001b[0;32m     76\u001b[0m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m序號\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m序號\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m答案\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_power\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m })\n",
      "Cell \u001b[1;32mIn[98], line 44\u001b[0m, in \u001b[0;36mpredict_minute_power\u001b[1;34m(targetdata, dateloc, start_time, end_time, features)\u001b[0m\n\u001b[0;32m     41\u001b[0m current_time \u001b[38;5;241m=\u001b[39m start_time\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m current_time \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m end_time:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# 預測每分鐘瓦數，這裡調用 predict_for_dataloc\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m     predicted_power \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_for_dataloc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdateloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     minute_predictions\u001b[38;5;241m.\u001b[39mappend(predicted_power)\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# 增加 1 分鐘\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[98], line 24\u001b[0m, in \u001b[0;36mpredict_for_dataloc\u001b[1;34m(dataloc, features, current_time)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     23\u001b[0m X_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(sequence, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 24\u001b[0m predicted_power \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted_power[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jeffi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jeffi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:448\u001b[0m, in \u001b[0;36mTensorFlowTrainer.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28mself\u001b[39m, x, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    446\u001b[0m ):\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;66;03m# Create an iterator that yields batches of input data.\u001b[39;00m\n\u001b[1;32m--> 448\u001b[0m     epoch_iterator \u001b[38;5;241m=\u001b[39m \u001b[43mTFEpochIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;66;03m# Container that configures and calls callbacks.\u001b[39;00m\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mc:\\Users\\jeffi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:666\u001b[0m, in \u001b[0;36mTFEpochIterator.__init__\u001b[1;34m(self, distribute_strategy, *args, **kwargs)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_strategy \u001b[38;5;241m=\u001b[39m distribute_strategy\n\u001b[1;32m--> 666\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedDataset):\n\u001b[0;32m    668\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribute_strategy\u001b[38;5;241m.\u001b[39mexperimental_distribute_dataset(\n\u001b[0;32m    669\u001b[0m         dataset\n\u001b[0;32m    670\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jeffi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:675\u001b[0m, in \u001b[0;36mTFEpochIterator._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_iterator\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tf_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jeffi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_data_adapter.py:140\u001b[0m, in \u001b[0;36mArrayDataAdapter.get_tf_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indices\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# We prefetch a single element. Computing large permutations can take\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# quite a while so we don't want to wait for prefetching over an epoch\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# boundary to trigger the next permutation. On the other hand, too many\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# simultaneous shuffles can contend on a hardware level and degrade all\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# performance.\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mindices_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpermutation\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslice_batch_indices\u001b[39m(indices):\n\u001b[0;32m    143\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m    This step can be accomplished in several ways. The most natural is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m        A Dataset of batched indices.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jeffi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1268\u001b[0m, in \u001b[0;36mDatasetV2.prefetch\u001b[1;34m(self, buffer_size, name)\u001b[0m\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprefetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, buffer_size, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetV2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1241\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a `Dataset` that prefetches elements from this dataset.\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m \n\u001b[0;32m   1243\u001b[0m \u001b[38;5;124;03m  Most dataset input pipelines should end with a call to `prefetch`. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;124;03m    A new `Dataset` with the transformation applied as described above.\u001b[39;00m\n\u001b[0;32m   1267\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1268\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprefetch_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prefetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m   1269\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jeffi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\prefetch_op.py:28\u001b[0m, in \u001b[0;36m_prefetch\u001b[1;34m(input_dataset, buffer_size, name)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[0;32m     27\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m input_dataset\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_PrefetchDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jeffi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\prefetch_op.py:46\u001b[0m, in \u001b[0;36m_PrefetchDataset.__init__\u001b[1;34m(self, input_dataset, buffer_size, slack_period, name)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# We colocate the prefetch dataset with its input as this collocation only\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# happens automatically in graph mode.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m---> 46\u001b[0m   variant_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefetch_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43mslack_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslack_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlegacy_autotune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTOTUNE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_common_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(input_dataset, variant_tensor)\n",
      "File \u001b[1;32mc:\\Users\\jeffi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:6177\u001b[0m, in \u001b[0;36mprefetch_dataset\u001b[1;34m(input_dataset, buffer_size, output_types, output_shapes, slack_period, legacy_autotune, buffer_size_min, metadata, name)\u001b[0m\n\u001b[0;32m   6175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   6176\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 6177\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   6178\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrefetchDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6179\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6180\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mslack_period\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslack_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlegacy_autotune\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlegacy_autotune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6181\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbuffer_size_min\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   6183\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 假設時間步長\n",
    "time_steps = 10\n",
    "\n",
    "# 預測函數：提取最近 time_steps 的數據\n",
    "def predict_for_dataloc(dataloc, features, current_time):\n",
    "    # 過濾當前時間之前的數據\n",
    "    df = pd.read_csv(f\"inputdata/{dataloc}.csv\")\n",
    "    df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "    valid_data = df[df['DateTime'] <= current_time]\n",
    "    \n",
    "    # 提取最近的 time_steps 條數據\n",
    "    sequence = valid_data[features].tail(time_steps).values\n",
    "    \n",
    "    # 確保數據量足夠\n",
    "    if len(sequence) < time_steps:\n",
    "        print(f\"數據不足，無法進行預測: {dataloc}, {current_time}\")\n",
    "        return 0.0\n",
    "    \n",
    "    X_input = np.expand_dims(sequence, axis=0).astype(np.float32)\n",
    "    predicted_power = model.predict(X_input)\n",
    "    return predicted_power[0][0]\n",
    "\n",
    "# 預測函數：計算每分鐘的預測瓦數並取平均\n",
    "def predict_minute_power(targetdata, dateloc, start_time, end_time, features):\n",
    "    # 過濾指定的 DateLoc\n",
    "    filtered_df = targetdata[targetdata['DateLoc'] == dateloc]\n",
    "\n",
    "    # 轉換 '序號' 為時間格式\n",
    "    filtered_df.loc[:, '序號'] = pd.to_datetime(filtered_df['序號'], format='%Y%m%d%H%M%S')\n",
    "\n",
    "    # 過濾時間範圍內的數據\n",
    "    filtered_df = filtered_df[(filtered_df['序號'] >= start_time) & (filtered_df['序號'] <= end_time)]\n",
    "    \n",
    "    # 如果範圍內有數據，計算每分鐘瓦數並取平均\n",
    "    if not filtered_df.empty:\n",
    "        minute_predictions = []\n",
    "        current_time = start_time\n",
    "        while current_time <= end_time:\n",
    "            # 預測每分鐘瓦數，這裡調用 predict_for_dataloc\n",
    "            predicted_power = predict_for_dataloc(dateloc, features, current_time)\n",
    "            minute_predictions.append(predicted_power)\n",
    "            \n",
    "            # 增加 1 分鐘\n",
    "            current_time += pd.Timedelta(minutes=1)\n",
    "\n",
    "        # 計算每分鐘瓦數的平均值\n",
    "        final_avg_power = np.mean(minute_predictions)\n",
    "    else:\n",
    "        final_avg_power = 0.0\n",
    "\n",
    "    return round(final_avg_power, 2)  # 返回最終的預測瓦數\n",
    "\n",
    "# 計算指定時間範圍內每分鐘的瓦數並取平均\n",
    "def generate_predictions(target_data, features, output_file):\n",
    "    \"\"\"\n",
    "    根據目標數據計算每段時間的每分鐘瓦數並生成結果文件。\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for _, row in target_data.iterrows():\n",
    "        # 提取序號信息\n",
    "        device_id = row['LocationCode']  # 使用當前行的 LocationCode\n",
    "        target_date = row['Date']  # 使用當前行的 Date\n",
    "        target_time = f\"{str(row['序號'])[8:10]}:{str(row['序號'])[10:12]}:00\"  # 提取起始時間\n",
    "        start_time = pd.Timestamp(f\"{target_date} {target_time}\")\n",
    "        end_time = start_time + pd.Timedelta(minutes=9, seconds=59)\n",
    "\n",
    "        # 預測該時間範圍內的瓦數\n",
    "        avg_power = predict_minute_power(target_data, row['DateLoc'], start_time, end_time, features)\n",
    "\n",
    "        # 添加結果到列表\n",
    "        results.append({\n",
    "            '序號': row['序號'],\n",
    "            '答案': f\"{avg_power:.2f}\"\n",
    "        })\n",
    "        print(f\"序號: {row['序號']}, 預測瓦數: {avg_power:.2f}\")\n",
    "\n",
    "    # 保存為 CSV 文件\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    print(f\"預測結果已成功儲存到 {output_file}！\")\n",
    "\n",
    "\n",
    "# 執行結果生成\n",
    "generate_predictions(target_data, features, 'upload_predictions.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
